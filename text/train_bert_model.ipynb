{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 256 # 128\n",
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 10\n",
    "LEARNING_RATE = 2e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [4794, 29189, 28528, 6, 11627, 794, 11, 77, 18765, 15, 10, 72, 5, 6157, 12, 31, 8], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import transformers\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertModel\n",
    "from torch import optim\n",
    "from torch import cuda\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from transformers import BertJapaneseTokenizer\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "# test\n",
    "path = './BERT-base_mecab-ipadic-bpe-32k'\n",
    "tokenizer = BertJapaneseTokenizer.from_pretrained(path, word_tokenizer_type='mecab')\n",
    "print(tokenizer.encode_plus(text='\\nいつぞや、日向地方を行乞した時の出来事である。', add_special_tokens=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = pd.read_csv('./train_author_novel.csv')[['author_id', 'filename']]\n",
    "classes = list(files['author_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>153</td>\n",
       "      <td>49679.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>281</td>\n",
       "      <td>3597.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>146</td>\n",
       "      <td>48246.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1670</td>\n",
       "      <td>54627.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>305</td>\n",
       "      <td>50390.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   author_id   filename\n",
       "0        153  49679.txt\n",
       "1        281   3597.txt\n",
       "2        146  48246.txt\n",
       "3       1670  54627.txt\n",
       "4        305  50390.txt"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, valid = train_test_split(files, test_size=0.2, shuffle=True, random_state=42, stratify=files['author_id'])\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "valid.reset_index(drop=True, inplace=True)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files(files, phase='train'):\n",
    "    texts = []\n",
    "    for filename in files:\n",
    "        with open(f'./pp_{phase}/{filename}') as f:\n",
    "            text = f.read()\n",
    "            text = text[:MAX_LEN*3] # bertのtokenize的に２〜3倍程度あれば大丈夫そう\n",
    "        texts.append(text)\n",
    "    return texts\n",
    "\n",
    "train_texts = read_files(list(train['filename']))\n",
    "train_auther_ids = list(train['author_id'])\n",
    "valid_texts = read_files(list(valid['filename']))\n",
    "valid_auther_ids = list(valid['author_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AozoraDataset(Dataset):\n",
    "    def __init__(self, texts, auther_ids, classes, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.auther_ids = auther_ids\n",
    "        self.classes = classes\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.auther_ids)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "          self.texts[index],\n",
    "          add_special_tokens=True,\n",
    "          max_length=self.max_len,\n",
    "          pad_to_max_length=True\n",
    "        )\n",
    "\n",
    "        labels = len(classes) * [0]\n",
    "        if self.auther_ids[index] is not None:\n",
    "            labels[self.classes.index(self.auther_ids[index])] = 1\n",
    "\n",
    "        return {\n",
    "          'ids': torch.LongTensor(inputs['input_ids']),\n",
    "          'mask': torch.LongTensor(inputs['attention_mask']),\n",
    "          'labels': torch.Tensor(labels)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/Users/imazekishouta/opt/anaconda3/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2016: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ids': tensor([    2,  2090,   114, 29333,   120,     7,  7330,    16,     6,  1325,\n",
       "             9,  5206, 28593,     6,  2894,   284,  6566, 28489,    16,  1276,\n",
       "            10,     8,     1,  2090,     7,  7330,    16,  1726,  1582,    12,\n",
       "             9,    80,     8,  1325,     5,  3246,     1, 12622,    16,  1276,\n",
       "            10,   732,     9,     6,     1,   319,     7,   830,    16, 26075,\n",
       "         28449, 24108, 31785,     5, 24108,     5,  2867,   465, 30794,  1346,\n",
       "         18147,  3488,    49, 28489,     7,     6,  1326,   114, 29333,   120,\n",
       "             1, 11367,     5,  1863,     7,  1040,     5,    36,  9467,    38,\n",
       "             5,    32,    52,    32,     7,  4192,    26,    20,    16,  1276,\n",
       "            10,   732,  3337,    12,    31,     8, 13818, 28545,  4914,  4914,\n",
       "             5,  1040,    11,  3649,    34,  1863,     7, 16166,     5,   493,\n",
       "         30642,    11,   474, 28647,  2078,    16,   212,    16,    28,     6,\n",
       "           218,    14,     6,  1037,    72,   962,   747,  4551,    32,     5,\n",
       "          1040,    11,  9109,    26,   191,  2298, 28532,    10,     8, 24108,\n",
       "             9, 17780,  4320, 28454,    10,     8,  1183,    14,  8508,    10,\n",
       "             8,  3459,   714,    32,     5,   284,     6,  1076,  8517,     5,\n",
       "            51,     7,   397,    11,   520,  1396,    16, 26075,    10,    49,\n",
       "         28489,    18,  1080,    14,  3563,    10,     8,  3608, 13818, 29665,\n",
       "             5,    51,     7,     6,  1040,     5,  4424,     5,  2049,    26,\n",
       "             7, 16760,    16,  6307,     5,    11,  1173,   181,    50, 13482,\n",
       "            16, 26075, 28449,    49, 28489,    18,  1080,    28,  3563,    10,\n",
       "             8,    26, 15184,    16,   744,     6,  3125,   922,   181,    10,\n",
       "          1052, 28751,    40,     6,  1040,     5,   226,    16,  1276,    10,\n",
       "         27579,    11,   474, 28647, 28449,    13,     6, 13818, 29285,     7,\n",
       "         16166,   325,   611,  4541,   146,    14,    31,    49, 28489,     7,\n",
       "           717, 28450,    62,     8,  1321,     3]),\n",
       " 'mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       " 'labels': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = AozoraDataset(train_texts, train_auther_ids, classes, tokenizer, MAX_LEN)\n",
    "valid_dataset = AozoraDataset(valid_texts, valid_auther_ids, classes, tokenizer, MAX_LEN)\n",
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AozoraClassficationModel(torch.nn.Module):\n",
    "    def __init__(self, path, output_size):\n",
    "        super().__init__()\n",
    "        self.bert = BertModel.from_pretrained(path)\n",
    "        self.ln = torch.nn.Linear(768, output_size)\n",
    "\n",
    "    def forward(self, ids, mask):\n",
    "        _, x = self.bert(ids, attention_mask=mask)\n",
    "        x = self.ln(x)\n",
    "        return x\n",
    "\n",
    "model = AozoraClassficationModel(path, len(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, device='cpu', criterion=None):\n",
    "    model.eval()\n",
    "    loss = 0.0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        print('*'*20 + 'start valid' + '*'*20)\n",
    "        for data in tqdm(loader):\n",
    "            ids = data['ids'].to(device)\n",
    "            mask = data['mask'].to(device)\n",
    "            labels = data['labels'].to(device)\n",
    "            outputs = model(ids, mask)\n",
    "            if criterion != None:\n",
    "                loss += criterion(outputs, labels).item()\n",
    "            pred = torch.argmax(outputs, dim=-1).cpu().numpy()\n",
    "            labels = torch.argmax(labels, dim=-1).cpu().numpy()\n",
    "            total += len(labels)\n",
    "            correct += (pred == labels).sum().item()\n",
    "\n",
    "    return loss / len(loader), correct / total\n",
    "\n",
    "def train_model(train_dataloader, valid_dataloader, model, criterion, optimizer, device='cpu'):\n",
    "    model.to(device)\n",
    "    train_log = []\n",
    "    valid_log = []\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        start = time.time()\n",
    "        model.train()\n",
    "        print('*'*20 + 'start train' + '*'*20)\n",
    "        for data in tqdm(train_dataloader):\n",
    "            ids = data['ids'].to(device)\n",
    "            mask = data['mask'].to(device)\n",
    "            labels = data['labels'].to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(ids, mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        train_loss, train_acc = evaluate(model, train_dataloader, device, criterion)\n",
    "        valid_loss, valid_acc = evaluate(model, valid_dataloader, device, criterion)\n",
    "        train_log.append([train_loss, train_acc])\n",
    "        valid_log.append([valid_loss, valid_acc])\n",
    "\n",
    "        torch.save({'epoch': epoch, 'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict()}, f'./models/checkpoint{epoch + 1}.pt')\n",
    "        end = time.time()\n",
    "        print(f'epoch: {epoch + 1}, loss_train: {train_loss:.4f}, accuracy_train: {train_acc:.4f}, loss_valid: {valid_loss:.4f}, accuracy_valid: {valid_acc:.4f}, {(end - start):.4f}sec') \n",
    "\n",
    "    return {'train': train_log, 'valid': valid_log}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************start train********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-b672be5eb6e5>:30: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for data in tqdm(train_dataloader):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eee3e83d33745749b77315d488a9700",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=80.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********************start valid********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-b672be5eb6e5>:8: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for data in tqdm(loader):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90ee82e823114b618df36bd2ac4d4c49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=80.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********************start valid********************\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f35456275b146f69870885aae68f0ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 1, loss_train: 0.2095, accuracy_train: 0.2408, loss_valid: 0.2098, accuracy_valid: 0.2327, 3394.1501sec\n",
      "********************start train********************\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0804c29c68a442ddb30c71d64e928ce0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=80.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********************start valid********************\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02d60b18b68a4f9996ba86f78c7fc26d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=80.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********************start valid********************\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db6a193d523945fcbe845cf2544f11f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 2, loss_train: 0.1643, accuracy_train: 0.5594, loss_valid: 0.1666, accuracy_valid: 0.5189, 3478.4826sec\n",
      "********************start train********************\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfc7248671f54f9abd28434db1c252de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=80.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********************start valid********************\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb799faa77884226b82fc33e872e9713",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=80.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********************start valid********************\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78a10a3a6669408eb87d272c94622dc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 3, loss_train: 0.1277, accuracy_train: 0.6703, loss_valid: 0.1361, accuracy_valid: 0.6069, 3548.2596sec\n",
      "********************start train********************\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "064d43ccadf643798deebae9341f1475",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=80.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********************start valid********************\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bad5470b03a347b198b2b2cbab5dcccf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=80.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********************start valid********************\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3cafe9850114fe7b5e96ba7a1d892b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 4, loss_train: 0.0948, accuracy_train: 0.8529, loss_valid: 0.1065, accuracy_valid: 0.7893, 3448.9762sec\n",
      "********************start train********************\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40925da952a04ceb89697f7b1e9870ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=80.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********************start valid********************\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70186bb55a0047ac9bb3bd5f545d75f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=80.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********************start valid********************\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f6c9cc9766a4f42aa81709526f0d11d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 5, loss_train: 0.0758, accuracy_train: 0.9064, loss_valid: 0.0952, accuracy_valid: 0.7767, 3365.9806sec\n",
      "********************start train********************\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d834738bdd0d425eae584d428b329b30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=80.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********************start valid********************\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee9f49fbc03d4bf4a76a6227fe37bcf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=80.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********************start valid********************\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "443586fb8bae4ef8a7d2bb3fcab51826",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 6, loss_train: 0.0542, accuracy_train: 0.9827, loss_valid: 0.0754, accuracy_valid: 0.8553, 3241.3957sec\n",
      "********************start train********************\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d6d2436e3204a0c9abd91373293bd76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=80.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********************start valid********************\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21080edbf92949b9a46b9f3172b53a42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=80.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********************start valid********************\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be3430134af647ff9c9048dbdcb064b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 7, loss_train: 0.0413, accuracy_train: 0.9921, loss_valid: 0.0659, accuracy_valid: 0.8679, 3414.5583sec\n",
      "********************start train********************\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1e7469a8a544a999e1d9aed7e2456c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=80.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********************start valid********************\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c4094721a004cd49111999dbcd7b816",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=80.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********************start valid********************\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a19b947bdd394581a4f27b117559a295",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 8, loss_train: 0.0323, accuracy_train: 0.9992, loss_valid: 0.0582, accuracy_valid: 0.8868, 3305.5577sec\n",
      "********************start train********************\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6d66e29b0f44e5aae1774031cb77df9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=80.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********************start valid********************\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2a1138e5fad4e8688177531693e89c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=80.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********************start valid********************\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "979d4173ebbf492cb63a2ee0233e2097",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 9, loss_train: 0.0264, accuracy_train: 1.0000, loss_valid: 0.0539, accuracy_valid: 0.8899, 3341.9573sec\n",
      "********************start train********************\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c550b8dc8bf349ecb118aeb35a14cc3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=80.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********************start valid********************\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15e6ac8b15c44ddd89b9d594a3fd1886",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=80.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********************start valid********************\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3139da73c33c4777a21d2a0856348e70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 10, loss_train: 0.0222, accuracy_train: 1.0000, loss_valid: 0.0502, accuracy_valid: 0.8994, 3309.7975sec\n"
     ]
    }
   ],
   "source": [
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.AdamW(params=model.parameters(), lr=LEARNING_RATE)\n",
    "log = train_model(train_dataloader, valid_dataloader, model, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AozoraClassficationModel(path, len(classes))\n",
    "model.load_state_dict(torch.load(f'./models/checkpoint10.pt')['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('./test_author_novel.csv')\n",
    "test['author_id'] = None\n",
    "\n",
    "test_texts = read_files(list(test['filename']), 'test')\n",
    "test_auther_ids = list(test['author_id'])\n",
    "\n",
    "test_dataset = AozoraDataset(test_texts, test_auther_ids, classes, tokenizer, MAX_LEN)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(test_dataloader, model, device='cpu'):\n",
    "    preds = []\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    for data in tqdm(test_dataloader):\n",
    "        ids = data['ids'].to(device)\n",
    "        mask = data['mask'].to(device)\n",
    "\n",
    "        outputs = model(ids, mask)\n",
    "        pred = torch.argmax(outputs, dim=-1).cpu().numpy()\n",
    "        preds += list(pred)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-60-753bc9769e5c>:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for data in tqdm(test_dataloader):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6be1d9775a28485ebd262c161d06bf02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=34.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "preds = inference(test_dataloader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>novel_id</th>\n",
       "      <th>filename</th>\n",
       "      <th>author_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2198</td>\n",
       "      <td>2198.txt</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2213</td>\n",
       "      <td>2213.txt</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2627</td>\n",
       "      <td>2627.txt</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2618</td>\n",
       "      <td>2618.txt</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2621</td>\n",
       "      <td>2621.txt</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   novel_id  filename  author_id\n",
       "0      2198  2198.txt          0\n",
       "1      2213  2213.txt          0\n",
       "2      2627  2627.txt          0\n",
       "3      2618  2618.txt         12\n",
       "4      2621  2621.txt         12"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['author_id'] = preds\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('./test_author_novel.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
